<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="mariaclark1123@outlook.com"><title>人工智能推荐算法库 - Suprise的介绍和应用 · Fang-da</title><meta name="description" content="Surprise简介Surprise（Simple Python Recommendation System Engine）是一款推荐系统库，是scikit系列中的一个，简单易用，同时支持多种推荐算法（基础算法、协同过滤、矩阵分解等）。
Surprise设计时考虑到以下目的：

让用户完美控制他们的"><meta name="keywords" content="Hexo,HTML,CSS,android,Linux"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/judy.jpg" style="width:160px;"><h3 title><a href="/" style="font-family:medium-ui-sans-serif-text-font,-apple-system,BlinkMacSystemFont,&quot;Segoe UI&quot;,Roboto,Oxygen,Ubuntu,Cantarell,&quot;Open Sans&quot;,&quot;Helvetica Neue&quot;,sans-serif;">Fang-da</a></h3><div class="description"><p>生活一分一秒的过, 你的斗志不是燃烧一刻，而是要每分每秒的燃烧, 即使不燃烧，至少不能让它熄灭。你要的斗志从来都不在逆境中, 而在你做成一件事后这件事能给你带来的成就感以及未来, 那是能指导你每分每秒都燃烧的火药。</p></div></div></div><ul class="social-links"><li><a href="http://facebook.com/mariaclark1123"><i class="fa fa-facebook"></i></a></li><li><a href="http://github.com/mariaclark1123"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"></a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Theme from Fangda&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/albums">相册</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>人工智能推荐算法库 - Suprise的介绍和应用</a></h3></div><div class="post-content"><h4 id="Surprise简介"><a href="#Surprise简介" class="headerlink" title="Surprise简介"></a>Surprise简介</h4><p><strong>Surprise（Simple Python Recommendation System Engine）</strong>是一款推荐系统库，是scikit系列中的一个，简单易用，同时支持多种推荐算法（基础算法、协同过滤、矩阵分解等）。</p>
<p><strong>Surprise设计时考虑到以下目的：</strong></p>
<ul>
<li>让用户完美控制他们的实验。为此，特别强调文档，试图通过指出算法的每个细节尽可能清晰和准确。</li>
<li>减轻数据集处理的痛苦。用户可以使用内置数据集（Movielens， Jester）和他们自己的自定义数据集。</li>
<li>提供各种即用型预测算法，例如基线算法，邻域方法，基于矩阵因子分解（SVD，PMF，SVD ++，NMF）等等。此外，内置了各种相似性度量（余弦，MSD，皮尔逊…）。</li>
<li>可以轻松实现新的算法思路。</li>
<li>提供评估，分析和比较算法性能的工具。使用强大的CV迭代器（受scikit-learn优秀工具启发）以及对一组参数的详尽搜索，可以非常轻松地运行交叉验证程序。<br>Surprise的主要特点是简单易用，同时支持多种推荐算法：</li>
</ul>
<h4 id="Surprise安装"><a href="#Surprise安装" class="headerlink" title="Surprise安装"></a>Surprise安装</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br><span class="line">pip install scikit-surprise</span><br></pre></td></tr></table></figure>
<p>在安装之前首先确认安装了numpy模块。</p>
<h4 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h4><div class="table-container">
<table>
<thead>
<tr>
<th>算法类名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor" target="_blank" rel="noopener">random_pred.NormalPredictor</a></td>
<td>根据训练集的分布特征随机给出一个预测值</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly" target="_blank" rel="noopener">baseline_only.BaselineOnly</a></td>
<td>给定用户和Item，给出基于baseline的估计值</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic" target="_blank" rel="noopener">knns.KNNBasic</a></td>
<td>最基础的协同过滤</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans" target="_blank" rel="noopener">knns.KNNWithMeans</a></td>
<td>将每个用户评分的均值考虑在内的协同过滤实现</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline" target="_blank" rel="noopener">knns.KNNBaseline</a></td>
<td>考虑基线评级的协同过滤</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD" target="_blank" rel="noopener">matrix_factorization.SVD</a></td>
<td>SVD实现</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp" target="_blank" rel="noopener">matrix_factorization.SVDpp</a></td>
<td>SVD++，即LFM+SVD</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF" target="_blank" rel="noopener">matrix_factorization.NMF</a></td>
<td>基于矩阵分解的协同过滤</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne" target="_blank" rel="noopener">slope_one.SlopeOne</a></td>
<td>一个简单但精确的协同过滤算法</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering" target="_blank" rel="noopener">co_clustering.CoClustering</a></td>
<td>基于协同聚类的协同过滤算法</td>
</tr>
</tbody>
</table>
</div>
<p><strong>其中基于近邻的方法(协同过滤)可以设定不同的度量准则</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>相似度度量标准</th>
<th>度量标准说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/similarities.html#surprise.similarities.cosine" target="_blank" rel="noopener">cosine</a></td>
<td>计算所有用户（或物品）对之间的余弦相似度</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/similarities.html#surprise.similarities.msd" target="_blank" rel="noopener">msd</a></td>
<td>计算所有用户（或物品）对之间的均方差异相似度</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/similarities.html#surprise.similarities.pearson" target="_blank" rel="noopener">pearson</a></td>
<td>计算所有用户（或物品）对之间的Pearson相关系数</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/similarities.html#surprise.similarities.pearson_baseline" target="_blank" rel="noopener">pearson_baseline</a></td>
<td>计算所有用户（或物品）对之间的（缩小的）Pearson相关系数，使用基线进行居中而不是平均值</td>
</tr>
</tbody>
</table>
</div>
<p><strong>支持不同的评估准则</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>评估准则</th>
<th>表头</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/accuracy.html#surprise.accuracy.rmse" target="_blank" rel="noopener">rmse</a></td>
<td>计算RMSE（均方根误差）</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/accuracy.html#surprise.accuracy.mae" target="_blank" rel="noopener">mae</a></td>
<td>计算MAE（平均绝对误差）</td>
</tr>
<tr>
<td><a href="http://surprise.readthedocs.io/en/stable/accuracy.html#surprise.accuracy.fcp" target="_blank" rel="noopener">fcp</a></td>
<td>计算FCP（协调对的分数）</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Surprise使用"><a href="#Surprise使用" class="headerlink" title="Surprise使用"></a>Surprise使用</h4><p><strong>（1）载入自带的数据集</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#-*- coding:utf-8 -*-</span><br><span class="line"># 可以使用上面提到的各种推荐系统算法</span><br><span class="line">from surprise import SVD</span><br><span class="line">from surprise import Dataset, print_perf</span><br><span class="line">from surprise.model_selection import cross_validate</span><br><span class="line"></span><br><span class="line"># 默认载入movielens数据集</span><br><span class="line">data = Dataset.load_builtin(&apos;ml-100k&apos;)</span><br><span class="line"># k折交叉验证(k=3),此方法现已弃用</span><br><span class="line"># data.split(n_folds=3)</span><br><span class="line"># 试一把SVD矩阵分解</span><br><span class="line">algo = SVD()</span><br><span class="line"># 在数据集上测试一下效果</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">#输出结果</span><br><span class="line">print_perf(perf)</span><br></pre></td></tr></table></figure>
<p><strong>（2）载入自己的数据集</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from surprise <span class="keyword">import</span> SVD</span><br><span class="line">from surprise <span class="keyword">import</span> Dataset, print_perf, Reader</span><br><span class="line">from surprise.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"># 指定文件所在路径</span><br><span class="line">file_path = os.path.expanduser('data.csv')</span><br><span class="line"># 告诉文本阅读器，文本的格式是怎么样的</span><br><span class="line">reader = Reader(line_format='user item rating', sep=',')</span><br><span class="line"># 加载数据</span><br><span class="line">data = Dataset.load_from_file(file_path, reader=reader)</span><br><span class="line">algo = SVD()</span><br><span class="line"># 在数据集上测试一下效果</span><br><span class="line">perf = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3)</span><br><span class="line">#输出结果</span><br><span class="line">print_perf(perf)</span><br></pre></td></tr></table></figure>
<p>需要注意：</p>
<p>1.无法识别中文，如果有中文，需要将其转换成ID号再进行操作（以下列出一种简单的转换方式）</p>
<p>2.不能有表头，需要去掉表头和元数据中有中文的列</p>
<p>3.需要修改Reader，line_format 就是数据的列，sep 是分隔方式（表格格式初始分割方式是‘,’）</p>
<p>一种简单的数据转换方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#-*- coding:utf-8 -*-</span><br><span class="line"># 构建物品id</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(&apos;train_score.csv&apos;, encoding=&quot;gbk&quot;)</span><br><span class="line"># 读取第二列的数据</span><br><span class="line">item_name = df.iloc[:, 1]</span><br><span class="line">item = &#123;&#125;</span><br><span class="line">item_id = []</span><br><span class="line">num = 0</span><br><span class="line"># 将每个不同的物品与id号进行关联</span><br><span class="line">for i in item_name:</span><br><span class="line">    if i in item:</span><br><span class="line">        item_id.append(item[i])</span><br><span class="line">    else:</span><br><span class="line">        item[i] = num</span><br><span class="line">        item_id.append(num)</span><br><span class="line">        num += 1</span><br><span class="line">print item_id</span><br><span class="line">df[&apos;itemId&apos;] = item_id</span><br><span class="line">df.to_csv(&quot;data.csv&quot;, encoding=&quot;gbk&quot;, index=False)</span><br></pre></td></tr></table></figure>
<h4 id="算法调参"><a href="#算法调参" class="headerlink" title="算法调参"></a>算法调参</h4><p>这里实现的算法用到的算法无外乎也是SGD等，因此也有一些超参数会影响最后的结果，我们同样可以用sklearn中常用到的网格搜索交叉验证(GridSearchCV)来选择最优的参数。简单的例子如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 定义好需要优选的参数网格</span><br><span class="line">param_grid = &#123;&apos;n_epochs&apos;: [5, 10], &apos;lr_all&apos;: [0.002, 0.005],</span><br><span class="line">              &apos;reg_all&apos;: [0.4, 0.6]&#125;</span><br><span class="line"># 使用网格搜索交叉验证</span><br><span class="line">grid_search = GridSearch(SVD, param_grid, measures=[&apos;RMSE&apos;, &apos;FCP&apos;])</span><br><span class="line"># 在数据集上找到最好的参数</span><br><span class="line">data = Dataset.load_builtin(&apos;ml-100k&apos;)</span><br><span class="line">data.split(n_folds=3)</span><br><span class="line">grid_search.evaluate(data)</span><br><span class="line"># 输出调优的参数组 </span><br><span class="line"># 输出最好的RMSE结果</span><br><span class="line">print(grid_search.best_score[&apos;RMSE&apos;])</span><br><span class="line"># &gt;&gt;&gt; 0.96117566386</span><br><span class="line"></span><br><span class="line"># 输出对应最好的RMSE结果的参数</span><br><span class="line">print(grid_search.best_params[&apos;RMSE&apos;])</span><br><span class="line"># &gt;&gt;&gt; &#123;&apos;reg_all&apos;: 0.4, &apos;lr_all&apos;: 0.005, &apos;n_epochs&apos;: 10&#125;</span><br><span class="line"></span><br><span class="line"># 最好的FCP得分</span><br><span class="line">print(grid_search.best_score[&apos;FCP&apos;])</span><br><span class="line"># &gt;&gt;&gt; 0.702279736531</span><br><span class="line"></span><br><span class="line"># 对应最高FCP得分的参数</span><br><span class="line">print(grid_search.best_params[&apos;FCP&apos;])</span><br><span class="line"># &gt;&gt;&gt; &#123;&apos;reg_all&apos;: 0.6, &apos;lr_all&apos;: 0.005, &apos;n_epochs&apos;: 10&#125;</span><br></pre></td></tr></table></figure>
<p><strong>GridSearchCV 方法：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 定义好需要优选的参数网格</span><br><span class="line">param_grid = &#123;&apos;n_epochs&apos;: [5, 10], &apos;lr_all&apos;: [0.002, 0.005],</span><br><span class="line">              &apos;reg_all&apos;: [0.4, 0.6]&#125;</span><br><span class="line"># 使用网格搜索交叉验证</span><br><span class="line">grid_search = GridSearchCV(SVD, param_grid, measures=[&apos;RMSE&apos;, &apos;FCP&apos;], cv=3)</span><br><span class="line"># 在数据集上找到最好的参数</span><br><span class="line">data = Dataset.load_builtin(&apos;ml-100k&apos;)</span><br><span class="line"># pref = cross_validate(grid_search, data, cv=3)</span><br><span class="line">grid_search.fit(data)</span><br><span class="line"># 输出调优的参数组</span><br><span class="line"># 输出最好的RMSE结果</span><br><span class="line">print(grid_search.best_score)</span><br></pre></td></tr></table></figure>
<h4 id="使用不同的推荐系统算法进行建模比较"><a href="#使用不同的推荐系统算法进行建模比较" class="headerlink" title="使用不同的推荐系统算法进行建模比较"></a>使用不同的推荐系统算法进行建模比较</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">from surprise import Dataset, print_perf</span><br><span class="line">from surprise.model_selection import cross_validate</span><br><span class="line">data = Dataset.load_builtin(&apos;ml-100k&apos;)</span><br><span class="line">### 使用NormalPredictor</span><br><span class="line">from surprise import NormalPredictor</span><br><span class="line">algo = NormalPredictor()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用BaselineOnly</span><br><span class="line">from surprise import BaselineOnly</span><br><span class="line">algo = BaselineOnly()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用基础版协同过滤</span><br><span class="line">from surprise import KNNBasic, evaluate</span><br><span class="line">algo = KNNBasic()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用均值协同过滤</span><br><span class="line">from surprise import KNNWithMeans, evaluate</span><br><span class="line">algo = KNNWithMeans()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用协同过滤baseline</span><br><span class="line">from surprise import KNNBaseline, evaluate</span><br><span class="line">algo = KNNBaseline()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用SVD</span><br><span class="line">from surprise import SVD, evaluate</span><br><span class="line">algo = SVD()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用SVD++</span><br><span class="line">from surprise import SVDpp, evaluate</span><br><span class="line">algo = SVDpp()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br><span class="line"></span><br><span class="line">### 使用NMF</span><br><span class="line">from surprise import NMF</span><br><span class="line">algo = NMF()</span><br><span class="line">perf = cross_validate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;], cv=3)</span><br><span class="line">print_perf(perf)</span><br></pre></td></tr></table></figure>
<h4 id="movielens推荐实例"><a href="#movielens推荐实例" class="headerlink" title="movielens推荐实例"></a>movielens推荐实例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">#-*- coding:utf-8 -*-</span><br><span class="line">from __future__ import (absolute_import, division, print_function,</span><br><span class="line">                        unicode_literals)</span><br><span class="line">import os</span><br><span class="line">import io</span><br><span class="line">from surprise import KNNBaseline</span><br><span class="line">from surprise import Dataset</span><br><span class="line"></span><br><span class="line">import logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.INFO,</span><br><span class="line">                    format=&apos;%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s&apos;,</span><br><span class="line">                    datefmt=&apos;%a， %d %b %Y %H:%M:%S&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 训练推荐模型 步骤:1</span><br><span class="line">def getSimModle():</span><br><span class="line">    # 默认载入movielens数据集</span><br><span class="line">    data = Dataset.load_builtin(&apos;ml-100k&apos;)</span><br><span class="line">    trainset = data.build_full_trainset()</span><br><span class="line">    #使用pearson_baseline方式计算相似度  False以item为基准计算相似度 本例为电影之间的相似度</span><br><span class="line">    sim_options = &#123;&apos;name&apos;: &apos;pearson_baseline&apos;, &apos;user_based&apos;: False&#125;</span><br><span class="line">    ##使用KNNBaseline算法</span><br><span class="line">    algo = KNNBaseline(sim_options=sim_options)</span><br><span class="line">    #训练模型</span><br><span class="line">    algo.fit(trainset)</span><br><span class="line">    return algo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取id到name的互相映射  步骤:2</span><br><span class="line">def read_item_names():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    获取电影名到电影id 和 电影id到电影名的映射</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    file_name = (os.path.expanduser(&apos;~&apos;) +</span><br><span class="line">                 &apos;/.surprise_data/ml-100k/ml-100k/u.item&apos;)</span><br><span class="line">    rid_to_name = &#123;&#125;</span><br><span class="line">    name_to_rid = &#123;&#125;</span><br><span class="line">    with io.open(file_name, &apos;r&apos;, encoding=&apos;ISO-8859-1&apos;) as f:</span><br><span class="line">        for line in f:</span><br><span class="line">            line = line.split(&apos;|&apos;)</span><br><span class="line">            rid_to_name[line[0]] = line[1]</span><br><span class="line">            name_to_rid[line[1]] = line[0]</span><br><span class="line">    return rid_to_name, name_to_rid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 基于之前训练的模型 进行相关电影的推荐  步骤：3</span><br><span class="line">def showSimilarMovies(algo, rid_to_name, name_to_rid):</span><br><span class="line">    # 获得电影Toy Story (1995)的raw_id</span><br><span class="line">    toy_story_raw_id = name_to_rid[&apos;Toy Story (1995)&apos;]</span><br><span class="line">    logging.debug(&apos;raw_id=&apos; + toy_story_raw_id)</span><br><span class="line">    #把电影的raw_id转换为模型的内部id</span><br><span class="line">    toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)</span><br><span class="line">    logging.debug(&apos;inner_id=&apos; + str(toy_story_inner_id))</span><br><span class="line">    #通过模型获取推荐电影 这里设置的是10部</span><br><span class="line">    toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, 10)</span><br><span class="line">    logging.debug(&apos;neighbors_ids=&apos; + str(toy_story_neighbors))</span><br><span class="line">    #模型内部id转换为实际电影id</span><br><span class="line">    neighbors_raw_ids = [algo.trainset.to_raw_iid(inner_id) for inner_id in toy_story_neighbors]</span><br><span class="line">    #通过电影id列表 或得电影推荐列表</span><br><span class="line">    neighbors_movies = [rid_to_name[raw_id] for raw_id in neighbors_raw_ids]</span><br><span class="line">    print(&apos;The 10 nearest neighbors of Toy Story are:&apos;)</span><br><span class="line">    for movie in neighbors_movies:</span><br><span class="line">        print(movie)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 获取id到name的互相映射</span><br><span class="line">    rid_to_name, name_to_rid = read_item_names()</span><br><span class="line"></span><br><span class="line">    # 训练推荐模型</span><br><span class="line">    algo = getSimModle()</span><br><span class="line"></span><br><span class="line">    ##显示相关电影</span><br><span class="line">    showSimilarMovies(algo, rid_to_name, name_to_rid)</span><br></pre></td></tr></table></figure>
<hr>
<p>参考文章：<br><a href="https://www.cnblogs.com/lzhc/p/9545134.html" target="_blank" rel="noopener">利用Surprise包进行电影推荐</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2020-07-20</span><i class="fa fa-tag"></i><a href="/tags/Machine-Learning/" title="Machine Learning" class="tag">Machine Learning </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://yoursite.com/2020/07/20/人工智能推荐算法库（一） -Suprise的介绍和应用/,Fang-da,人工智能推荐算法库 - Suprise的介绍和应用,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2020/07/20/人工智能推荐算法（一） - 协同过滤算法介绍/" title="人工智能推荐算法（一） - 协同过滤算法介绍" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2020/05/29/励志的程序员们（五）/" title="励志的程序员们（五）" class="btn">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>